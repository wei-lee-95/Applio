{
  "Training": "トレーニング",
  "Extra": "おまけ",
  "Processing": "加工",
  "Inference": "推論",
  "Output Information": "出力情報",
  "Merge Audios": "オーディオのマージ",
  "Preprocess": "前処理",
  "Settings": "設定",
  "Audio Analyzer": "オーディオアナライザー",
  "Plugins": "プラグイン",
  "Report a Bug": "バグの報告",
  "Model Information": "モデル情報",
  "Download": "ダウンロード",
  "Model Name": "モデル名",
  "Audio cutting": "オーディオ分割",
  "The output information will be displayed here.": "出力情報がここに表示されます。",
  "Process effects": "エフェクトを処理",
  "Dataset Path": "データセットパス",
  "Name of the new model.": "新しいモデルの名前。",
  "Dataset Name": "データセット名",
  "Refresh Datasets": "データセットの更新",
  "This section contains some extra utilities that often may be in experimental phases.": "このセクションには、実験段階にあることが多い追加のユーティリティがいくつか含まれています。",
  "Dataset Creator": "データセットクリエーター",
  "A simple, high-quality voice conversion tool focused on ease of use and performance.": "使いやすさとパフォーマンスにこだわったシンプルで高品質な音声変換ツール。",
  "Path to the dataset folder.": "データセットフォルダーへのパス。",
  "Enter model name": "モデル名を入力してください",
  "It's recommended to deactivate this option if your dataset has already been processed.": "データセットがすでに処理されている場合は、このオプションを無効にすることをお勧めします。",
  "Enter dataset name": "データセット名を入力",
  "Name of the new dataset.": "新しいデータセットの名前。",
  "Upload Audio Dataset": "オーディオデータセットのアップロード",
  "Extract": "抜く",
  "The audio file has been successfully added to the dataset. Please click the preprocess button.": "オーディオ ファイルがデータセットに正常に追加されました。前処理ボタンをクリックしてください。",
  "Enter dataset path": "データセットのパスを入力",
  "Preprocess Dataset": "データセットの前処理",
  "Sampling Rate": "サンプリングレート",
  "Model Architecture": "モデルアーキテクチャ",
  "Hop Length": "ホップ長",
  "Version of the model architecture.": "モデルアーキテクチャのバージョン。",
  "Embedder Model": "埋め込みモデル",
  "The sampling rate of the audio files.": "オーディオファイルのサンプリングレート。",
  "Batch Size": "バッチサイズ",
  "Save Every Epoch": "すべてのエポックを保存",
  "Total Epoch": "合計エポック",
  "Model used for learning speaker embedding.": "スピーカー埋め込みの学習に使用されたモデル。",
  "Pretrained": "事前学習済みモデルを使用する",
  "Save Only Latest": "最新のみ保存",
  "Save Every Weights": "すべてのウェイトを保存",
  "Determine at how many epochs the model will saved at.": "モデルが何エポックで保存されるかを決定します。",
  "Custom Pretrained": "カスタム事前トレーニング済みモデル",
  "Upload Pretrained Model": "事前学習済みモデルのアップロード",
  "Denotes the duration it takes for the system to transition to a significant pitch change. Smaller hop lengths require more time for inference but tend to yield higher pitch accuracy.": "システムがピッチの大幅な変化に移行するのにかかる時間を示します。ホップ長が小さいほど、推論に時間がかかりますが、ピッチ精度が高くなる傾向があります。",
  "Specifies the overall quantity of epochs for the model training process.": "モデル学習プロセスの全体的なエポック数を指定します。",
  "GPU Settings": "GPU設定",
  "Refresh Custom Pretraineds": "カスタム事前トレーニング済みモデルの更新",
  "It's advisable to align it with the available VRAM of your GPU. A setting of 4 offers improved accuracy but slower processing, while 8 provides faster and standard results.": "GPUの利用可能なVRAMに合わせることをお勧めします。4 に設定すると精度は向上しますが処理は遅くなり、8 に設定するとより高速で標準的な結果が得られます。",
  "Pretrained D Path": "カスタム事前学習済みDモデル",
  "This setting enables you to save the weights of the model at the conclusion of each epoch.": "この設定により、各エポックの終了時にモデルの重みを保存できます。",
  "Pretrained G Path": "カスタム事前トレーニング済みGモデル",
  "GPU Number": "GPU番号",
  "The file you dropped is not a valid pretrained file. Please try again.": "ドロップしたファイルは有効な事前学習済みファイルではありません。もう一度お試しください。",
  "GPU Custom Settings": "GPUカスタム設定",
  "Pretrained Custom Settings": "事前トレーニング済みモデルのカスタム設定",
  "The GPU information will be displayed here.": "ここにGPU情報が表示されます。",
  "0 to ∞ separated by -": "0 から ∞ は - で区切られます。",
  "Enabling this setting will result in the G and D files saving only their most recent versions, effectively conserving storage space.": "この設定を有効にすると、GファイルとDファイルは最新バージョンのみを保存するため、ストレージスペースが効果的に節約されます。",
  "GPU Information": "GPU情報",
  "Sets advanced GPU settings, recommended for users with better GPU architecture.": "GPU アーキテクチャが優れているユーザーに推奨される高度な GPU 設定を設定します。",
  "Pitch Guidance": "ピッチガイダンス",
  "Use CPU": "CPU を使用する",
  "Click the refresh button to see the pretrained file in the dropdown menu.": "更新ボタンをクリックすると、ドロップダウンメニューに事前学習済みファイルが表示されます。",
  "Force the use of CPU for training.": "トレーニングに CPU の使用を強制します。",
  "The number of CPU cores to use in the preprocess. The default setting are your cpu cores, which is recommended for most cases.": "前処理で使用する CPU コアの数。デフォルト設定はCPUコアであり、ほとんどの場合に推奨されます。",
  "The number of CPU cores to use in the extraction process. The default setting are your cpu cores, which is recommended for most cases.": "抽出プロセスで使用する CPU コアの数。デフォルト設定はCPUコアであり、ほとんどの場合に推奨されます。",
  "Extract Features": "特徴量の抽出",
  "Specify the number of GPUs you wish to utilize for preprocess by entering them separated by hyphens (-). At the moment, using multi-gpu will not have a significant effect.": "前処理に使用するGPUの数をハイフン(-)で区切って入力して指定します。現時点では、マルチGPUを使用しても大きな影響はありません。",
  "Cache Dataset in GPU": "GPU でのデータセットのキャッシュ",
  "Specify the number of GPUs you wish to utilize for extracting by entering them separated by hyphens (-).": "抽出に使用するGPUの数をハイフン(-)で区切って入力します。",
  "Index Algorithm": "インデックスアルゴリズム",
  "Utilizing custom pretrained models can lead to superior results, as selecting the most suitable pretrained models tailored to the specific use case can significantly enhance performance.": "カスタムの事前学習済みモデルを利用すると、特定のユースケースに合わせて最適な事前学習済みモデルを選択することでパフォーマンスを大幅に向上させることができるため、優れた結果を得ることができます。",
  "We prioritize running the model preprocessing on the GPU for faster performance. If you prefer to use the CPU, simply leave the GPU field blank.": "パフォーマンスを高速化するために、モデルの前処理を GPU で実行することを優先します。CPU を使用する場合は、GPU フィールドを空白のままにします。",
  "We prioritize running the model extraction on the GPU for faster performance. If you prefer to use the CPU, simply leave the GPU field blank.": "パフォーマンスを高速化するために、モデル抽出を GPU で実行することを優先します。CPU を使用する場合は、GPU フィールドを空白のままにします。",
  "Overtraining Detector": "過学習検出",
  "Utilize pretrained models when training your own. This approach reduces training duration and enhances overall quality.": "独自のモデルをトレーニングする場合は、事前トレーニング済みのモデルを利用します。このアプローチにより、トレーニング時間が短縮され、全体的な品質が向上します。",
  "Fresh Training": "フレッシュトレーニング",
  "Cache the dataset in GPU memory to speed up the training process.": "データセットをGPUメモリにキャッシュして、トレーニングプロセスを高速化します。",
  "Overtraining Threshold": "過学習のしきい値",
  "Overtraining Detector Settings": "過学習検出の設定",
  "Start Training": "トレーニングを開始",
  "By employing pitch guidance, it becomes feasible to mirror the intonation of the original voice, including its pitch. This feature is particularly valuable for singing and other scenarios where preserving the original melody or pitch pattern is essential.": "ピッチガイダンスを採用することで、ピッチを含む元の声のイントネーションを反映させることが可能になります。この機能は、歌唱や、元のメロディーやピッチパターンを保持することが不可欠なその他のシナリオで特に役立ちます。",
  "KMeans is a clustering algorithm that divides the dataset into K clusters. This setting is particularly useful for large datasets.": "KMeansは、データセットをK個のクラスターに分割するクラスタリングアルゴリズムです。この設定は、大規模なデータセットに特に役立ちます。",
  "Generate Index": "インデックスの生成",
  "Export Model": "モデルのエクスポート",
  "Stop Training": "トレーニングの停止",
  "Exported Pth file": "エクスポートされた Pth ファイル",
  "Exported Index file": "エクスポートされたインデックスファイル",
  "Upload": "アップロード",
  "Index File": "インデックスファイル",
  "Voice Model": "音声モデル",
  "Enable this setting only if you are training a new model from scratch or restarting the training. Deletes all previously generated weights and tensorboard logs.": "この設定は、新しいモデルを最初からトレーニングする場合、またはトレーニングを再開する場合にのみ有効にします。以前に生成された重みとテンソルボードのログをすべて削除します。",
  "Refresh": "リフレッシュ",
  "Set the maximum number of epochs you want your model to stop training if no improvement is detected.": "改善が検出されない場合にモデルのトレーニングを停止するエポックの最大数を設定します。",
  "Select the pth file to be exported": "エクスポートするpthファイルを選択します",
  "Select the index file to be exported": "エクスポートするインデックスファイルを選択します",
  "Unload Voice": "モデルのアンロード",
  "Single": "単一ファイル",
  "Detect overtraining to prevent the model from learning the training data too well and losing the ability to generalize to new data.": "過学習を検出して、モデルがトレーニング データを十分に学習しすぎて、新しいデータに一般化する能力を失うのを防ぎます。",
  "Select Audio": "オーディオを選択",
  "Select the voice model to use for the conversion.": "変換に使用する音声モデルを選択します。",
  "Select the index file to use for the conversion.": "変換に使用するインデックスファイルを選択します。",
  "The button 'Upload' is only for google colab: Uploads the exported files to the ApplioExported folder in your Google Drive.": "「アップロード」ボタンはGoogle Colab専用です:エクスポートしたファイルをGoogleドライブのApplioExportedフォルダにアップロードします。",
  "Upload Audio": "オーディオのアップロード",
  "Select the audio to convert.": "変換するオーディオを選択します。",
  "Advanced Settings": "詳細設定",
  "Output Path": "出力パス",
  "Export Format": "エクスポート形式",
  "Custom Output Path": "カスタム出力パス",
  "Autotune": "オートチューン",
  "Split Audio": "オーディオの分割",
  "Select the format to export the audio.": "オーディオをエクスポートする形式を選択します。",
  "Clean Audio": "オーディオをクリーニング",
  "Clean Strength": "クリーニング強度",
  "Upscale Audio": "オーディオをアップスケールする",
  "Clear Outputs (Deletes all audios in assets/audios)": "出力をクリア (アセット/オーディオ内のすべてのオーディオを削除します)",
  "The path where the output audio will be saved, by default in assets/audios/output.wav": "出力オーディオが保存されるパス (デフォルトでは assets/audios/output.wav",
  "Formant Shifting": "フォルマントシフティング",
  "Presets are located in /assets/formant_shift folder": "プリセットは /assets/formant_shift フォルダにあります",
  "Split the audio into chunks for inference to obtain better results in some cases.": "オーディオをチャンクに分割して推論します.場合によってはより良い結果を得ることができます。",
  "Browse presets for formanting": "フォルマンティングのプリセットを参照",
  "Default value is 1.0": "デフォルト値は 1.0 です",
  "Apply a soft autotune to your inferences, recommended for singing conversions.": "推論にソフトオートチューンを適用し、歌声の変換に推奨します。",
  "Pitch": "ピッチ",
  "Quefrency for formant shifting": "フォルマントシフトのためのケフレンシー",
  "Upscale the audio to a higher quality, recommended for low-quality audios. (It could take longer to process the audio)": "オーディオを高品質にアップスケールします (低品質のオーディオに推奨)。(オーディオの処理に時間がかかる場合があります)",
  "Timbre for formant shifting": "フォルマントシフトのための音色",
  "Filter Radius": "フィルター半径",
  "Enable formant shifting. Used for male to female and vice-versa convertions.": "フォルマントシフトを有効にします。男性から女性へ、またはその逆の変換に使用されます。",
  "Clean your audio output using noise detection algorithms, recommended for speaking audios.": "ノイズ検出アルゴリズムを使用してオーディオ出力をクリーニングします。これは、音声の読み上げに推奨されます。",
  "Volume Envelope": "ボリュームエンベロープ",
  "Convert": "変換",
  "Batch": "バッチ",
  "Set the clean-up level to the audio you want, the more you increase it the more it will clean up, but it is possible that the audio will be more compressed.": "クリーンアップレベルを希望のオーディオに設定し、上げるほどクリーンアップされますが、オーディオがより圧縮される可能性があります。",
  "Set the pitch of the audio, the higher the value, the higher the pitch.": "オーディオのピッチを設定し、値が高いほどピッチが高くなります。",
  "Export Audio": "オーディオのエクスポート",
  "Search Feature Ratio": "検索特徴量の割合",
  "Protect Voiceless Consonants": "無声子音の保護",
  "Pitch extraction algorithm": "ピッチ抽出アルゴリズム",
  "Input Folder": "入力フォルダ",
  "Influence exerted by the index file; a higher value corresponds to greater influence. However, opting for lower values can help mitigate artifacts present in the audio.": "インデックスファイルによって及ぼされる影響。値が大きいほど、影響が大きくなります。ただし、低い値を選択すると、オーディオに存在するアーティファクトを軽減するのに役立ちます。",
  "Output Folder": "出力フォルダ",
  "Enter input path": "入力パスを入力",
  "Substitute or blend with the volume envelope of the output. The closer the ratio is to 1, the more the output envelope is employed.": "出力のボリュームエンベロープに置き換えるか、ブレンドします。比率が1に近いほど、出力エンベロープがより多く使用されます。",
  "Pitch extraction algorithm to use for the audio conversion. The default algorithm is rmvpe, which is recommended for most cases.": "オーディオ変換に使用するピッチ抽出アルゴリズム。デフォルトのアルゴリズムは rmvpe で、ほとんどの場合に推奨されます。",
  "Enter output path": "出力パスを入力",
  "Select the folder containing the audios to convert.": "変換するオーディオを含むフォルダを選択します。",
  "Voice Blender": "ボイスブレンダー",
  "Select the folder where the output audios will be saved.": "出力オーディオを保存するフォルダを選択します。",
  "If the number is greater than or equal to three, employing median filtering on the collected tone results has the potential to decrease respiration.": "数値が 3 以上の場合、収集されたトーン結果に中央値フィルタリングを使用すると、呼吸が減少する可能性があります。",
  "Drag and drop your model here": "ここにモデルをドラッグアンドドロップします",
  "Fusion": "融合",
  "Blend Ratio": "ブレンド比率",
  "Safeguard distinct consonants and breathing sounds to prevent electro-acoustic tearing and other artifacts. Pulling the parameter to its maximum value of 0.5 offers comprehensive protection. However, reducing this value might decrease the extent of protection while potentially mitigating the indexing effect.": "明確な子音と呼吸音を保護して、電気音響の引き裂きやその他のアーティファクトを防ぎます。パラメータを最大値の 0.5 にプルすると、包括的な保護が提供されます。ただし、この値を小さくすると、保護の範囲が減少する一方で、インデックス作成の影響が軽減される可能性があります。",
  "You can also use a custom path.": "カスタムパスを使用することもできます。",
  "View model information": "モデル情報の表示",
  "Model information to be placed": "配置するモデル情報",
  "Path to Model": "モデルへのパス",
  "Inroduce the model information": "モデル情報の提供",
  "Select two voice models, set your desired blend percentage, and blend them into an entirely new voice.": "2 つの音声モデルを選択し、希望のブレンド率を設定して、まったく新しい音声にブレンドします。",
  "Enter path to model": "モデルへのパスを入力",
  "Model extraction": "モデルを抽出",
  "View": "表示する",
  "Model conversion": "モデル変換",
  "Pth file": "Pth ファイル",
  "The information to be placed in the model (You can leave it blank or put anything).": "モデルに配置する情報(空白のままにするか、何でも入れることができます)。",
  "Output of the pth file": "pth ファイルの出力",
  "Extract F0 Curve": "F0 カーブを抽出",
  "Record": "記録",
  "Record Screen": "画面録画",
  "# How to Report an Issue on GitHub": "# GitHubで問題を報告する方法",
  "Adjusting the position more towards one side or the other will make the model more similar to the first or second.": "位置をどちらか一方に調整すると、モデルは1番目または2番目により近くなります。",
  "3. Go to [GitHub Issues](https://github.com/IAHispano/Applio/issues) and click on the 'New Issue' button.": "3. [GitHub Issues](https://github.com/IAHispano/Applio/issues)に移動し、[New Issue]ボタンをクリックします。",
  "Stop Recording": "録音を停止する",
  "Introduce the model .pth path": "モデルの.pthパスを導入",
  "See Model Information": "モデル情報を見る",
  "## Download Model": "## ダウンロードモデル",
  "1. Click on the 'Record Screen' button below to start recording the issue you are experiencing.": "1.下の[画面の記録]ボタンをクリックして、発生している問題の記録を開始します。",
  "Model Link": "モデルリンク",
  "Get information about the audio": "オーディオに関する情報を取得する",
  "## Voice Blender": "## ボイスブレンダー",
  "Download Model": "モデルのダウンロード",
  "Introduce the model link": "モデルリンクを紹介",
  "## Drop files": "## ファイルをドロップ",
  "Drag your .pth file and .index file into this space. Drag one and then the other.": ".pth ファイルと .index ファイルをこのスペースにドラッグします。一方をドラッグしてから、もう一方をドラッグします。",
  "Search": "捜索",
  "## Search Model": "## 検索モデル",
  "2. Once you have finished recording the issue, click on the 'Stop Recording' button (the same button, but the label changes depending on whether you are actively recording or not).": "2.問題の録音が終了したら、[録音の停止]ボタンをクリックします(同じボタンですが、アクティブに録音しているかどうかによってラベルが変わります)。",
  "Introduce the model pth path": "モデルのpthパスを紹介",
  "We couldn't find models by that name.": "その名前のモデルは見つかりませんでした。",
  "TTS Speed": "TTSスピード",
  "Introduce the model name to search.": "検索するモデル名を紹介します。",
  "TTS Voices": "TTSボイス",
  "The f0 curve represents the variations in the base frequency of a voice over time, showing how pitch rises and falls.": "f0 曲線は、時間の経過に伴う音声の基本周波数の変化を表し、ピッチがどのように上昇および下降するかを示します。",
  "Increase or decrease TTS speed.": "TTS速度を増減します。",
  "## Download Pretrained Models": "## 事前学習済みモデルのダウンロード",
  "Select the TTS voice to use for the conversion.": "変換に使用する TTS 音声を選択します。",
  "Text to Synthesize": "合成するテキスト",
  "4. Complete the provided issue template, ensuring to include details as needed, and utilize the assets section to upload the recorded file from the previous step.": "4. 提供された問題テンプレートを完成させ、必要に応じて詳細を含めるようにし、アセットセクションを使用して前のステップで記録したファイルをアップロードします。",
  "And select the sampling rate": "そして、サンプリングレートを選択します。",
  "Upload a .txt file": ".txtファイルをアップロードする",
  "Enter the text to synthesize.": "合成するテキストを入力します。",
  "Select the pretrained model you want to download.": "ダウンロードする事前学習済みモデルを選択します。",
  "Input path for text file": "テキストファイルの入力パス",
  "Enter text to synthesize": "合成するテキストを入力する",
  "Output Path for TTS Audio": "TTS オーディオの出力パス",
  "Output Path for RVC Audio": "RVCオーディオの出力パス",
  "Enable Applio integration with Discord presence": "Applio と Discord プレゼンスの統合を有効にする",
  "Enable fake GPU": "フェイクGPUを有効にする",
  "Restart Applio": "Applioを再起動します",
  "Enable Applio integration with applio.org/models using flask": "Flaskを使用してApplioと applio.org/models の統合を有効にする",
  "The path to the text file that contains content for text to speech.": "テキスト読み上げのコンテンツを含むテキスト ファイルへのパス。",
  "Precision": "精度",
  "It will activate the possibility of downloading models with a click from the website.": "Webサイトからクリックするだけでモデルをダウンロードすることが可能になります。",
  "It will activate the possibility of displaying the current Applio activity in Discord.": "これにより、Discordで現在のApplioアクティビティを表示が有効になります。",
  "Select the theme you want to use. (Requires restarting Applio)": "使用するテーマを選択します。(Applioの再起動が必要です)",
  "Language": "言語",
  "Training is currently unsupported due to the absence of a GPU. To activate the training tab, navigate to the settings tab and enable the 'Fake GPU' option.": "GPU がないため、トレーニングは現在サポートされていません。トレーニングタブを有効にするには、設定タブに移動し、「Fake GPU」オプションを有効にします。",
  "Select the language you want to use. (Requires restarting Applio)": "使用する言語を選択します。(Applioの再起動が必要です)",
  "Theme": "テーマ",
  "Update precision": "使用する精度を更新する",
  "Drag your plugin.zip to install it": "plugin.zipをドラッグしてインストールします",
  "Plugin Installer": "プラグインインストーラー",
  "Activates the train tab. However, please note that this device lacks GPU capabilities, hence training is not supported. This option is only for testing purposes. (This option will restart Applio)": "[トレーニング] タブをアクティブにします。ただし、このデバイスにはGPU機能がないため、トレーニングには対応していないことに注意してください。このオプションは、テストのみを目的としています。(このオプションはApplioを再起動します)",
  "Version Checker": "バージョンチェッカー",
  "Reverb": "リバーブ",
  "Post-Process": "後処理",
  "Check for updates": "アップデートの確認",
  "Select the precision you want to use for training and inference.": "トレーニングと推論に使用する精度を選択します。",
  "Reverb Room Size": "リバーブルームサイズ",
  "Reverb Damping": "リバーブダンピング",
  "Set the room size of the reverb.": "リバーブの部屋のサイズを設定します。",
  "Apply reverb to the audio.": "オーディオにリバーブを適用します。",
  "Reverb Wet Gain": "リバーブウェットゲイン",
  "Post-process the audio to apply effects to the output.": "オーディオを後処理して、出力にエフェクトを適用します。",
  "Reverb Dry Gain": "リバーブドライゲイン",
  "Set the wet gain of the reverb.": "リバーブのウェットゲインを設定します。",
  "Reverb Width": "リバーブ幅",
  "Check which version of Applio is the latest to see if you need to update.": "Applioのどのバージョンが最新かを確認して、更新が必要かどうかを確認してください。",
  "Set the damping of the reverb.": "リバーブのダンピングを設定します。",
  "Set the dry gain of the reverb.": "リバーブのドライゲインを設定します。",
  "Set the width of the reverb.": "リバーブの幅を設定します。",
  "Set the freeze mode of the reverb.": "リバーブのフリーズモードを設定します。",
  "Pitch Shift": "ピッチシフト",
  "Reverb Freeze Mode": "リバーブフリーズモード",
  "Limiter": "リミッタ",
  "Apply pitch shift to the audio.": "オーディオにピッチシフトを適用します。",
  "Pitch Shift Semitones": "ピッチシフト半音",
  "Gain": "得",
  "Distortion": "歪み",
  "Apply limiter to the audio.": "オーディオにリミッターを適用します。",
  "Set the pitch shift semitones.": "ピッチシフトを半音に設定します。",
  "Limiter Threshold dB": "リミッターしきい値dB",
  "Gain dB": "ゲインdB",
  "Limiter Release Time": "リミッターリリースタイム",
  "Set the limiter threshold dB.": "リミッターしきい値 dB を設定します。",
  "Set the gain dB.": "ゲインdBを設定します。",
  "Apply gain to the audio.": "オーディオにゲインを適用します。",
  "Chorus": "コーラス",
  "Set the limiter release time.": "リミッターのリリース時間を設定します。",
  "Apply distortion to the audio.": "オーディオに歪みを適用します。",
  "Set the distortion gain.": "ディストーションゲインを設定します。",
  "Chorus Rate Hz": "コーラスレート Hz",
  "Apply chorus to the audio.": "オーディオにコーラスを適用します。",
  "Set the chorus depth.": "コーラスの深さを設定します。",
  "Chorus Depth": "コーラスの深さ",
  "Chorus Feedback": "コーラスフィードバック",
  "Set the chorus rate Hz.": "コーラスレートをHzに設定します。",
  "Distortion Gain": "ディストーションゲイン",
  "Chorus Center Delay ms": "コーラスセンターディレイms",
  "Bitcrush": "ビットクラッシュ",
  "Set the chorus mix.": "コーラスミックスを設定します。",
  "Set the chorus feedback.": "コーラスのフィードバックを設定します。",
  "Chorus Mix": "コーラスミックス",
  "Bitcrush Bit Depth": "Bitcrushビット深度",
  "Set the chorus center delay ms.": "コーラスの中心ディレイmsを設定します。",
  "Apply bitcrush to the audio.": "オーディオにbitcrushを適用します。",
  "Clipping": "クリッピング",
  "Compressor": "コンプレッサー",
  "Set the bitcrush bit depth.": "bitcrush ビット深度を設定します。",
  "Apply clipping to the audio.": "オーディオにクリッピングを適用します。",
  "Clipping Threshold": "クリッピングしきい値",
  "Set the clipping threshold.": "クリッピングのしきい値を設定します。",
  "Delay": "ディレイ",
  "Apply compressor to the audio.": "オーディオにコンプレッサーを適用します。",
  "Compressor Threshold dB": "コンプレッサーしきい値dB",
  "Compressor Ratio": "コンプレッサー比",
  "Set the compressor ratio.": "コンプレッサー比を設定します。",
  "Apply delay to the audio.": "オーディオにディレイを適用します。",
  "Set the compressor attack ms.": "コンプレッサーのアタックmsを設定します。",
  "Set the compressor release ms.": "コンプレッサーのリリースmsを設定します。",
  "Set the compressor threshold dB.": "コンプレッサーのしきい値dBを設定します。",
  "Compressor Release ms": "コンプレッサーリリースミリ秒",
  "Compressor Attack ms": "コンプレッサーアタックms",
  "Delay Seconds": "ディレイ秒数",
  "Set the delay seconds.": "ディレイ秒数を設定します。",
  "Set the delay mix.": "ディレイミックスを設定します。",
  "Set the delay feedback.": "ディレイフィードバックを設定します。",
  "Delay Mix": "ディレイミックス",
  "Custom Embedder": "カスタムエンベッダー",
  "Refresh embedders": "埋め込みのリフレッシュ",
  "model information": "モデル情報",
  "Upload .bin": ".binをアップロード",
  "Delay Feedback": "ディレイフィードバック",
  "Upload .json": ".jsonをアップロード",
  "Select Custom Embedder": "カスタム埋め込みを選択します",
  "Model Creator": "モデルクリエーター",
  "Speaker ID": "スピーカーID",
  "Move files to custom embedder folder": "ファイルをカスタム埋め込みフォルダーに移動する",
  "Name of the model creator. (Default: Unknown)": "モデルの作成者の名前。(デフォルト: Unknown)",
  "The name that will appear in the model information.": "モデル情報に表示される名前。",
  "Set name": "名前を設定する",
  "Folder Name": "フォルダ名",
  "Select the speaker ID to use for the conversion.": "変換に使用するスピーカー ID を選択します。",
  "Model Author Name": "モデル作成者名",
  "Set the autotune strength - the more you increase it the more it will snap to the chromatic grid.": "オートチューンの強さを設定します - 上げるほど、クロマチックグリッドにスナップします。"
}
